---
title: "Homework 2"
author: "Shaolei Ma"
date: "`r Sys.Date()`"
output: github_document
---

```{r libraries, echo = F, message = F, results = "hide"}
options(scipen = 999) # force all the numbers to appear as decimals.
library(tidyverse)
library(readxl)
library(ggplot2)
```

# Problem 1

First, clean the data in `pols-month.csv`.

```{r}
pols_df =
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-", 
           convert = T) |> # convert to integers
  arrange(year, month) |> # order before months are replaced with names
  mutate(
    month = month.abb[month], # change to abbr to merge with unemployment data set
    president = case_when(
    prez_dem == 1 ~ "dem",
    prez_gop == 1 ~ "gop"
    )) |> 
  select(-prez_dem, -prez_gop, -day) |> 
  relocate(year, month, president)
```

Second, clean the data in `snp.csv` using a similar process to the above.

```{r}
snp_df = 
  read_csv("data/fivethirtyeight_datasets/snp.csv",
           col_types = cols(date = col_date(format = "%m/%d/%y"))) |> 
  janitor::clean_names() |> 
  mutate(date = ifelse(
    date > Sys.Date(),
    format(date, "19%y-%m-%d"),
    format(date)
  )) |> # correct the century
  separate(date, into = c("year", "month", "day"), sep = "-", 
           convert = T) |> 
  arrange(year, month) |>
  mutate(month = month.abb[month]) |> 
  select(-day) |> 
  relocate(year, month)
```

Third, tidy the `unemployment` data so that it can be merged with the previous datasets.

```{r}
unemployment_df =
  read_csv("data/fivethirtyeight_datasets/unemployment.csv") |> 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemploy_rate"
  ) |> 
  janitor::clean_names()
```

Join the datasets by merging `snp` into `pols`, and merging `unemployment` into the result.

```{r}
result_df = 
  pols_df |> 
  left_join(snp_df,
            by = join_by(year, month)) |> 
  left_join(unemployment_df,
            by = join_by(year, month))
```

The cleaned data set `pols-month` contains `r nrow(pols_df)` observations of `r ncol(pols_df)` variables related to the number of national politicians who are democratic or republican at any given time from `r min(pull(pols_df, year))` to `r max(pull(pols_df, year))`. The cleaned data set `snp` contains `r nrow(snp_df)` observations of `r ncol(snp_df)` variables related to Standard & Poorâ€™s stock market index (S&P), often used as a representative measure of stock market as a whole, from `r min(pull(snp_df, year))` to `r max(pull(snp_df, year))`. The cleaned data set `unemployment` contains `r nrow(unemployment_df)` observations of `r ncol(unemployment_df)` variables related to the unemployment rate in any given month from `r min(pull(unemployment_df, year))` to `r max(pull(unemployment_df, year))`.  
For the resulting data set, it contains `r nrow(result_df)` observations of `r ncol(result_df)` variables related to all three parts of information mentioned above in a given month from `r paste(pull(pols_df, month)[1], min(pull(pols_df, year)), sep = ", ")` to `r paste(pull(pols_df, month)[nrow(pols_df)], max(pull(pols_df, year)), sep = ", ")`. Specifically, the `president` variable indicates whether the president was republican (gop) or democratic (dem) on the associated date; the `close` variable indicates the closing values of the S&P stock index on the associated date; the `unemploy_rate` variable indicates the percentage of unemployment on the associated date.

# Problem 2

Read and clean the Mr. Trash Wheel sheet:

```{r}
mr_trash_wheel_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:M587") |> 
  janitor::clean_names() |> # use reasonable variable names
  drop_na(dumpster) |> # omit rows that do not include dumpster-specific data
  mutate(homes_powered = weight_tons * 500 / 30,
         year = as.numeric(year), # alter the type of year
         name = "Mr") # add a column to specify
```

Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda.

```{r}
prof_trash_wheel_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:L109") |> 
  janitor::clean_names() |> # use reasonable variable names
  drop_na(dumpster) |> # omit rows that do not include dumpster-specific data
  mutate(homes_powered = weight_tons * 500 / 30,
         name = "Professor")

gwy_trash_wheel_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:K159") |> 
  janitor::clean_names() |> # use reasonable variable names
  drop_na(dumpster) |> # omit rows that do not include dumpster-specific data
  mutate(homes_powered = weight_tons * 500 / 30,
         name = "Gwynnda")
```

Then, combine the three datasets.

```{r}
trash_wheel_df = 
  mr_trash_wheel_df |> 
  full_join(prof_trash_wheel_df) |> 
  full_join(gwy_trash_wheel_df) |> 
  relocate(name) # put the name of the trash wheel front
```

The three given data sets are all related to the total weight and volume of the trash, the number of different waste products, the number of the dumpster, and the number of households the trash equates to in terms of electricity on a given date.  
Specifically, the cleaned **Mr. Trash Wheel** data set contains `r nrow(mr_trash_wheel_df)` observations of `r ncol(mr_trash_wheel_df)` variables from `r paste(pull(mr_trash_wheel_df, month)[1], min(pull(mr_trash_wheel_df, year)), sep = ", ")` to `r paste(pull(mr_trash_wheel_df, month)[nrow(mr_trash_wheel_df)], max(pull(mr_trash_wheel_df, year)), sep = ", ")`. The cleaned **Professor Trash Wheel** data set contains `r nrow(prof_trash_wheel_df)` observations of `r ncol(prof_trash_wheel_df)` variables from `r paste(pull(prof_trash_wheel_df, month)[1], min(pull(prof_trash_wheel_df, year)), sep = ", ")` to `r paste(pull(prof_trash_wheel_df, month)[nrow(prof_trash_wheel_df)], max(pull(prof_trash_wheel_df, year)), sep = ", ")`. the cleaned **Gwynnda Trash Wheel** data set contains `r nrow(gwy_trash_wheel_df)` observations of `r ncol(gwy_trash_wheel_df)` variables from `r paste(pull(gwy_trash_wheel_df, month)[1], min(pull(prof_trash_wheel_df, year)), sep = ", ")` to `r paste(pull(prof_trash_wheel_df, month)[nrow(gwy_trash_wheel_df)], max(pull(prof_trash_wheel_df, year)), sep = ", ")`.  
For the resulting dataset, it contains `r nrow(trash_wheel_df)` observations of `r ncol(trash_wheel_df)` variables, among which the `name` variable marks the trash wheel's name (`r trash_wheel_df |> pull(name) |> unique()`). It can be concluded that the total weight of trash collected by Professor Trash Wheel is `r prof_trash_wheel_df |> pull(weight_tons) |> sum()` and the total number of cigarette butts collected by Gwynnda in July of 2021 is `r gwy_trash_wheel_df |> filter(year == 2021 & month == "July") |> pull(cigarette_butts) |> sum()`.

# Problem 3

Import, clean, and tidy the dataset of baseline demographics.

```{r}
mci_baseline_df = 
  read_csv("data/data_mci/MCI_baseline.csv", skip = 1, # skip the first row
           na = c(".", "NA")) |> # treat the missing value as NA
  janitor::clean_names() |> 
  mutate(
    sex = case_match(
      sex,
      1 ~ "Male",
      0 ~ "Female"
    ),
    apoe4 = case_match(
      apoe4,
      1 ~ "APOE4 carrier",
      0 ~ "APOE4 non-carrier"
    )
  )

# collect the participants that fail to reach the criteria
id_removed = mci_baseline_df |> 
  filter(current_age >= age_at_onset) |> 
  pull(id)

# remove the participants from the dataset
mci_baseline_df = 
  mci_baseline_df |> 
  filter(current_age < age_at_onset | is.na(age_at_onset) == 1)
```

For the data cleaning, first I skipped the first row which contains notes for the columns, and treated the missing values as `NA` for convenience afterwards. The `case_match` step converts the numerical values of the `sex` and `apoe4` variables to their original meanings for readability. In the end, I compared the `current_age` variable and `age_at_onset` variable to ensure the MCI onset happens after baseline. After cleaning, the data set contains  `r nrow(mci_baseline_df)` observations of `r ncol(mci_baseline_df)` variables.  
From the data set, it could be concluded that `r nrow(read_csv("data/data_mci/MCI_baseline.csv", skip = 1))` participants in total were recruited, among which `r nrow(mci_baseline_df)` participants met the criteria, and `r mci_baseline_df |> filter(is.na(age_at_onset) != 1) |> nrow()` develop MCI. After the participants who do not meet the criteria are removed, the average baseline age is `r mci_baseline_df |> pull(current_age) |> mean() |> round(2)`, and `r mci_baseline_df |> filter(sex == "Female" & apoe4 == "APOE4 carrier") |> nrow() / mci_baseline_df |> filter(sex == "Female") |> nrow() * 100`% of women in the study are APOE4 carriers.  

Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values.

```{r}
mci_amyloid_df = 
  read_csv("data/data_mci/mci_amyloid.csv", skip = 1, # skip the first row
           na = c("NA", "Na")) |>
  janitor::clean_names() |> 
  pivot_longer(
    baseline:time_8,
    names_to = "time_in_years",
    names_prefix = "time_",
    values_to = "amyloid_beta_42_40_ratio"
  ) |> 
  mutate( # change baseline to 0 year
    time_in_years = replace(time_in_years, time_in_years == "baseline", 0),
    amyloid_beta_42_40_ratio = as.numeric(amyloid_beta_42_40_ratio)
  ) |> # move the participants that do not meet the criteria
  filter(!study_id %in% id_removed)
```

For the data cleaning, first I skipped the first row which contains notes for the columns, and treated "Na" and "NA" both as `NA` values because there is an "Na" value inside the "Baseline" variable. Then I converted the five variables measuring the ratio at a given time into two variables named "time_in_years" and "amyloid_beta_42_40_ratio". Finally, I removed the participants who do not meet the criteria in the baseline dataset. After cleaning, the data set contains `r nrow(mci_amyloid_df)` observations of `r ncol(mci_amyloid_df)` variables. The ratio distribution for different years is illustrated below:

```{r}
mci_amyloid_df |> 
  ggplot(aes(y = amyloid_beta_42_40_ratio, x = time_in_years)) + 
  geom_boxplot()
```

From the boxplot, it could be concluded that as the number of years increases, the ratio tends to drop in overall. 

## Compare the two datasets.

Check whether some participants appear in only the baseline or amyloid datasets.

```{r}
all_participants_df =
  mci_baseline_df |> 
  full_join(mci_amyloid_df, by = join_by(id == study_id),
            keep = T) # keep both id and study_id for comparision
```

Then, `r all_participants_df |> filter(is.na(id)) |> pull(study_id) |> unique() |> length()` participants are only in the amyloid datset, `r sum(is.na(pull(all_participants_df, study_id)))` participants are only in the baseline datset.  
Retain only the participants who appear in both datasets.

```{r}
both_participants_df = 
  mci_baseline_df |> 
  inner_join(mci_amyloid_df, by = join_by(id == study_id))
write_csv(both_participants_df, "data/data_mci/mci_result.csv") # export
```

The result contains `r nrow(both_participants_df)` observations of `r ncol(both_participants_df)` variables related to the participants' baseline demographics and amyloid $\beta$ 42/40 ratio measured every two years from the baseline to the eighth year. Among the `r both_participants_df |> pull(id) |> unique() |> length()` participants, `r both_participants_df |> filter(sex == "Female") |> pull(id) |> unique() |> length()` are female, `r both_participants_df |> filter(apoe4 == "APOE4 carrier") |> pull(id) |> unique() |> length()` are APOE4 carriers. The average current age at baseline is `r both_participants_df |> pull(current_age) |> mean() |> round(2)`, and the average length of education at baseline is `r both_participants_df |> pull(education) |> mean() |> round(2)` years.